import locale
locale.getpreferredencoding = lambda : "UTF-8"
!pip install -q transformers ffmpeg pydub


#import model Vin AI
from transformers import pipeline
transcriber = pipeline("automatic-speech-recognition", model="vinai/PhoWhisper-large", device="cuda")


from IPython.display import Javascript
from google.colab import output
from base64 import b64decode
from io import BytesIO
RECORD = """
const sleep  = time => new Promise(resolve => setTimeout(resolve, time))
const b2text = blob => new Promise(resolve => {
  const reader = new FileReader()
  reader.onloadend = e => resolve(e.srcElement.result)
  reader.readAsDataURL(blob)
})
var record = time => new Promise(async resolve => {
  stream = await navigator.mediaDevices.getUserMedia({ audio: true })
  recorder = new MediaRecorder(stream)
  chunks = []
  recorder.ondataavailable = e => chunks.push(e.data)
  recorder.start()
  await sleep(time)
  recorder.onstop = async ()=>{
    blob = new Blob(chunks)
    text = await b2text(blob)
    resolve(text)
  }
  recorder.stop()
})
"""

def voice_to_text(sec=5):
  print("Đang ghi âm....")
  display(Javascript(RECORD))
  s = output.eval_js('record(%d)' % (sec*1000))
  b = b64decode(s.split(',')[1])
  path_file_wav ='/content/kien.wav'
  with open(path_file_wav, "wb") as f:
    f.write(b)
  #Kết thúc ghi âm. Gửi tới model convert
  result = transcriber(path_file_wav)
  return result["text"]


voice_to_text()
